# -*- coding: utf-8 -*-
"""DL_Project1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A0pPwCi0DPzMTPN3Iyr6feukfSe-_zho
"""

import numpy as np
import pandas as pd 
from keras.preprocessing.image import ImageDataGenerator, load_img
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import random
import os
from google.colab import drive 
drive.mount('/content/gdrive')

import pickle # load the train data 
pickle_in = open("/content/gdrive/My Drive/DL_Project_1/project1/train/X_train.pickle","rb")
X_train = pickle.load(pickle_in) 
X_train = X_train/255.0 # normalize the image data

pickle_in_y = open("/content/gdrive/My Drive/DL_Project_1/project1/train/y_train.pickle","rb")
y_train = pickle.load(pickle_in_y)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D
model = Sequential()
model.add(Conv2D(64,(3,3), activation = 'relu', input_shape = X_train.shape[1:]))
model.add(MaxPooling2D(pool_size = (2,2)))

model.add(Conv2D(64,(3,3), activation = 'relu'))
model.add(MaxPooling2D(pool_size = (2,2)))

model.add(Conv2D(64,(3,3), activation = 'relu'))
model.add(MaxPooling2D(pool_size = (2,2)))

model.add(Flatten())
model.add(Dense(32, activation='relu'))
# Add a softmax layer with 10 output units:
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer="adam",
              loss='binary_crossentropy',
              metrics=['accuracy'])

import pickle
pickle_in = open("/content/gdrive/My Drive/DL_Project_1/project1/validation/X_validation.pickle","rb")
X_validation = pickle.load(pickle_in) 
X_validation = X_validation/255.0 # normalize the image data

pickle_in_y = open("/content/gdrive/My Drive/DL_Project_1/project1/validation/y_validation.pickle","rb")
y_validation = pickle.load(pickle_in_y)

history = model.fit(X_train, y_train, epochs=10, validation_data = (X_validation, y_validation), batch_size=128)

model.save('/content/gdrive/My Drive/DL_Project_1/project1/train/X_train.h5')
print("Model saved")

from numpy import loadtxt
from tensorflow.keras.models import load_model
import keras
import h5py
# load model
model1 = load_model('/content/gdrive/My Drive/DL_Project_1/project1/train/X_train.h5')
# summarize model.
model1.summary()

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

predictions = model1.predict(X_validation)

print(y_validation[190])

layer_dict = dict([(layer.name, layer) for layer in model1.layers])

layer_dict

filters, biases = layer_dict['conv2d'].get_weights()

f_min, f_max = np.amin(filters), np.amax(filters)
filters = (filters - f_min) / (f_max - f_min)

filters.shape

n_filters, index = 6, 1
for i in range(n_filters):
    f = filters[:, :, :, i]
    
    # Plot each channel separately
    for j in range(3):

        ax = plt.subplot(n_filters, 3, index)
        ax.set_xticks([])
        ax.set_yticks([])
        
        plt.imshow(f[:, :, j], cmap='viridis')
        index += 1
        
plt.show()

X_validation.shape

from tensorflow.keras.models import Model

model = Model(inputs=model1.inputs, outputs=model1.layers[0].output)

test_image = X_validation[0]
test_image = test_image.reshape((1, 150, 150, 3))
test_image.shape

feature_maps = model.predict(test_image)
feature_maps.shape

square = 8
index = 1
for _ in range(square):
	for _ in range(square):
        
		ax = plt.subplot(square, square, index)
		ax.set_xticks([])
		ax.set_yticks([])
		plt.imshow(feature_maps[0, :, :, index-1], cmap='viridis')
		index += 1
        
plt.show()

